{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import numpy as np\n",
    "from torch import nn, argmax\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from sklearn.decomposition import PCA\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch\n",
    "import sys\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "\n",
    "# get X_test, X_train, and y_train np arrays\n",
    "data = loadmat('data.mat')\n",
    "X_test = data['X_test']\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "y_train = y_train.transpose()\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "y_train = y_train.reshape(-1)\n",
    "X_train, X_test = scaleData(X_train, X_test)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(x_tr, x_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_tr)\n",
    "    x_tr = scaler.transform(x_tr)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    return x_tr, x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 1.09455 | train_accuracy: 0.43219 | train_balanced_accuracy: 0.50555 | val_accuracy: 0.43232 | val_balanced_accuracy: 0.50329 |  0:00:11s\n",
      "epoch 1  | loss: 0.94968 | train_accuracy: 0.48924 | train_balanced_accuracy: 0.55266 | val_accuracy: 0.49058 | val_balanced_accuracy: 0.54971 |  0:00:22s\n",
      "epoch 2  | loss: 0.90488 | train_accuracy: 0.53699 | train_balanced_accuracy: 0.58003 | val_accuracy: 0.53905 | val_balanced_accuracy: 0.57735 |  0:00:33s\n",
      "epoch 3  | loss: 0.87237 | train_accuracy: 0.56198 | train_balanced_accuracy: 0.59997 | val_accuracy: 0.56088 | val_balanced_accuracy: 0.59625 |  0:00:45s\n",
      "epoch 4  | loss: 0.85162 | train_accuracy: 0.59613 | train_balanced_accuracy: 0.61501 | val_accuracy: 0.59483 | val_balanced_accuracy: 0.60968 |  0:00:56s\n",
      "epoch 5  | loss: 0.83353 | train_accuracy: 0.60618 | train_balanced_accuracy: 0.62445 | val_accuracy: 0.60447 | val_balanced_accuracy: 0.61958 |  0:01:08s\n",
      "epoch 6  | loss: 0.82159 | train_accuracy: 0.60601 | train_balanced_accuracy: 0.63047 | val_accuracy: 0.60507 | val_balanced_accuracy: 0.62711 |  0:01:19s\n",
      "epoch 7  | loss: 0.81041 | train_accuracy: 0.59566 | train_balanced_accuracy: 0.63305 | val_accuracy: 0.59562 | val_balanced_accuracy: 0.62988 |  0:01:31s\n",
      "epoch 8  | loss: 0.80293 | train_accuracy: 0.62624 | train_balanced_accuracy: 0.6396  | val_accuracy: 0.62508 | val_balanced_accuracy: 0.63588 |  0:01:43s\n",
      "epoch 9  | loss: 0.79794 | train_accuracy: 0.62106 | train_balanced_accuracy: 0.64376 | val_accuracy: 0.61992 | val_balanced_accuracy: 0.63861 |  0:01:54s\n",
      "epoch 10 | loss: 0.7925  | train_accuracy: 0.60408 | train_balanced_accuracy: 0.64132 | val_accuracy: 0.60342 | val_balanced_accuracy: 0.63769 |  0:02:05s\n",
      "epoch 11 | loss: 0.78991 | train_accuracy: 0.63528 | train_balanced_accuracy: 0.64801 | val_accuracy: 0.63387 | val_balanced_accuracy: 0.64174 |  0:02:16s\n",
      "epoch 12 | loss: 0.787   | train_accuracy: 0.63375 | train_balanced_accuracy: 0.65027 | val_accuracy: 0.63214 | val_balanced_accuracy: 0.64436 |  0:02:28s\n",
      "epoch 13 | loss: 0.78399 | train_accuracy: 0.61233 | train_balanced_accuracy: 0.64934 | val_accuracy: 0.61145 | val_balanced_accuracy: 0.64509 |  0:02:40s\n",
      "epoch 14 | loss: 0.78092 | train_accuracy: 0.64221 | train_balanced_accuracy: 0.65038 | val_accuracy: 0.64051 | val_balanced_accuracy: 0.64467 |  0:02:51s\n",
      "epoch 15 | loss: 0.77716 | train_accuracy: 0.63044 | train_balanced_accuracy: 0.6542  | val_accuracy: 0.62839 | val_balanced_accuracy: 0.64763 |  0:03:03s\n",
      "epoch 16 | loss: 0.77722 | train_accuracy: 0.64693 | train_balanced_accuracy: 0.65401 | val_accuracy: 0.64415 | val_balanced_accuracy: 0.64653 |  0:03:14s\n",
      "epoch 17 | loss: 0.77283 | train_accuracy: 0.62823 | train_balanced_accuracy: 0.65143 | val_accuracy: 0.62555 | val_balanced_accuracy: 0.64571 |  0:03:25s\n",
      "epoch 18 | loss: 0.77359 | train_accuracy: 0.63413 | train_balanced_accuracy: 0.65665 | val_accuracy: 0.632   | val_balanced_accuracy: 0.64948 |  0:03:37s\n",
      "epoch 19 | loss: 0.77082 | train_accuracy: 0.63457 | train_balanced_accuracy: 0.65727 | val_accuracy: 0.63227 | val_balanced_accuracy: 0.64961 |  0:03:48s\n",
      "epoch 20 | loss: 0.76921 | train_accuracy: 0.66129 | train_balanced_accuracy: 0.65159 | val_accuracy: 0.65976 | val_balanced_accuracy: 0.64621 |  0:04:00s\n",
      "epoch 21 | loss: 0.76531 | train_accuracy: 0.64837 | train_balanced_accuracy: 0.66031 | val_accuracy: 0.64485 | val_balanced_accuracy: 0.65191 |  0:04:11s\n",
      "epoch 22 | loss: 0.76204 | train_accuracy: 0.64911 | train_balanced_accuracy: 0.65997 | val_accuracy: 0.64605 | val_balanced_accuracy: 0.65249 |  0:04:23s\n",
      "epoch 23 | loss: 0.76293 | train_accuracy: 0.64243 | train_balanced_accuracy: 0.65841 | val_accuracy: 0.63937 | val_balanced_accuracy: 0.65063 |  0:04:34s\n",
      "epoch 24 | loss: 0.76205 | train_accuracy: 0.63908 | train_balanced_accuracy: 0.6627  | val_accuracy: 0.63471 | val_balanced_accuracy: 0.65305 |  0:04:46s\n",
      "epoch 25 | loss: 0.75788 | train_accuracy: 0.63559 | train_balanced_accuracy: 0.66454 | val_accuracy: 0.63128 | val_balanced_accuracy: 0.65507 |  0:04:57s\n",
      "epoch 26 | loss: 0.75703 | train_accuracy: 0.63349 | train_balanced_accuracy: 0.6626  | val_accuracy: 0.63182 | val_balanced_accuracy: 0.65458 |  0:05:09s\n",
      "epoch 27 | loss: 0.76004 | train_accuracy: 0.63405 | train_balanced_accuracy: 0.66044 | val_accuracy: 0.63124 | val_balanced_accuracy: 0.65189 |  0:05:20s\n",
      "epoch 28 | loss: 0.75773 | train_accuracy: 0.6322  | train_balanced_accuracy: 0.66591 | val_accuracy: 0.62901 | val_balanced_accuracy: 0.65559 |  0:05:31s\n",
      "epoch 29 | loss: 0.75387 | train_accuracy: 0.64772 | train_balanced_accuracy: 0.66751 | val_accuracy: 0.64328 | val_balanced_accuracy: 0.65628 |  0:05:43s\n",
      "epoch 30 | loss: 0.75245 | train_accuracy: 0.63077 | train_balanced_accuracy: 0.66484 | val_accuracy: 0.62718 | val_balanced_accuracy: 0.65429 |  0:05:55s\n",
      "epoch 31 | loss: 0.75149 | train_accuracy: 0.65151 | train_balanced_accuracy: 0.66759 | val_accuracy: 0.64777 | val_balanced_accuracy: 0.65711 |  0:06:06s\n",
      "epoch 32 | loss: 0.75    | train_accuracy: 0.63864 | train_balanced_accuracy: 0.66946 | val_accuracy: 0.63329 | val_balanced_accuracy: 0.65716 |  0:06:17s\n",
      "epoch 33 | loss: 0.74839 | train_accuracy: 0.64909 | train_balanced_accuracy: 0.66949 | val_accuracy: 0.64569 | val_balanced_accuracy: 0.65832 |  0:06:29s\n",
      "epoch 34 | loss: 0.74822 | train_accuracy: 0.639   | train_balanced_accuracy: 0.67089 | val_accuracy: 0.6342  | val_balanced_accuracy: 0.65755 |  0:06:40s\n",
      "epoch 35 | loss: 0.74447 | train_accuracy: 0.65569 | train_balanced_accuracy: 0.67048 | val_accuracy: 0.65046 | val_balanced_accuracy: 0.65724 |  0:06:52s\n",
      "epoch 36 | loss: 0.74507 | train_accuracy: 0.65243 | train_balanced_accuracy: 0.66887 | val_accuracy: 0.64814 | val_balanced_accuracy: 0.65829 |  0:07:03s\n",
      "epoch 37 | loss: 0.75122 | train_accuracy: 0.62608 | train_balanced_accuracy: 0.66281 | val_accuracy: 0.62097 | val_balanced_accuracy: 0.64978 |  0:07:15s\n",
      "epoch 38 | loss: 0.75869 | train_accuracy: 0.637   | train_balanced_accuracy: 0.66752 | val_accuracy: 0.63399 | val_balanced_accuracy: 0.65698 |  0:07:27s\n",
      "epoch 39 | loss: 0.75071 | train_accuracy: 0.6465  | train_balanced_accuracy: 0.67039 | val_accuracy: 0.6426  | val_balanced_accuracy: 0.65915 |  0:07:38s\n",
      "epoch 40 | loss: 0.74534 | train_accuracy: 0.64513 | train_balanced_accuracy: 0.67107 | val_accuracy: 0.64105 | val_balanced_accuracy: 0.65927 |  0:07:50s\n",
      "epoch 41 | loss: 0.74575 | train_accuracy: 0.64432 | train_balanced_accuracy: 0.6708  | val_accuracy: 0.63888 | val_balanced_accuracy: 0.65829 |  0:08:01s\n",
      "epoch 42 | loss: 0.74821 | train_accuracy: 0.64446 | train_balanced_accuracy: 0.67202 | val_accuracy: 0.63952 | val_balanced_accuracy: 0.65858 |  0:08:13s\n",
      "epoch 43 | loss: 0.74285 | train_accuracy: 0.64315 | train_balanced_accuracy: 0.67103 | val_accuracy: 0.63724 | val_balanced_accuracy: 0.65704 |  0:08:25s\n",
      "epoch 44 | loss: 0.73995 | train_accuracy: 0.6326  | train_balanced_accuracy: 0.66787 | val_accuracy: 0.62689 | val_balanced_accuracy: 0.65418 |  0:08:36s\n",
      "epoch 45 | loss: 0.74092 | train_accuracy: 0.64533 | train_balanced_accuracy: 0.6748  | val_accuracy: 0.63927 | val_balanced_accuracy: 0.66074 |  0:08:48s\n",
      "epoch 46 | loss: 0.73893 | train_accuracy: 0.66046 | train_balanced_accuracy: 0.67391 | val_accuracy: 0.65513 | val_balanced_accuracy: 0.66013 |  0:08:59s\n",
      "epoch 47 | loss: 0.73778 | train_accuracy: 0.65471 | train_balanced_accuracy: 0.67657 | val_accuracy: 0.64902 | val_balanced_accuracy: 0.66317 |  0:09:11s\n",
      "epoch 48 | loss: 0.73621 | train_accuracy: 0.65813 | train_balanced_accuracy: 0.67669 | val_accuracy: 0.65184 | val_balanced_accuracy: 0.66161 |  0:09:22s\n",
      "epoch 49 | loss: 0.73558 | train_accuracy: 0.65507 | train_balanced_accuracy: 0.67657 | val_accuracy: 0.64778 | val_balanced_accuracy: 0.65984 |  0:09:34s\n",
      "epoch 50 | loss: 0.73526 | train_accuracy: 0.64605 | train_balanced_accuracy: 0.67761 | val_accuracy: 0.64133 | val_balanced_accuracy: 0.66497 |  0:09:45s\n",
      "epoch 51 | loss: 0.73174 | train_accuracy: 0.64398 | train_balanced_accuracy: 0.67779 | val_accuracy: 0.6372  | val_balanced_accuracy: 0.66298 |  0:09:58s\n",
      "epoch 52 | loss: 0.73229 | train_accuracy: 0.65051 | train_balanced_accuracy: 0.67941 | val_accuracy: 0.64355 | val_balanced_accuracy: 0.66267 |  0:10:09s\n",
      "epoch 53 | loss: 0.73248 | train_accuracy: 0.66339 | train_balanced_accuracy: 0.67381 | val_accuracy: 0.65768 | val_balanced_accuracy: 0.6603  |  0:10:21s\n",
      "epoch 54 | loss: 0.73402 | train_accuracy: 0.64202 | train_balanced_accuracy: 0.6781  | val_accuracy: 0.63624 | val_balanced_accuracy: 0.66407 |  0:10:31s\n",
      "epoch 55 | loss: 0.72899 | train_accuracy: 0.66134 | train_balanced_accuracy: 0.67912 | val_accuracy: 0.65615 | val_balanced_accuracy: 0.66419 |  0:10:43s\n",
      "epoch 56 | loss: 0.73264 | train_accuracy: 0.65916 | train_balanced_accuracy: 0.67814 | val_accuracy: 0.65299 | val_balanced_accuracy: 0.6633  |  0:10:54s\n",
      "epoch 57 | loss: 0.73483 | train_accuracy: 0.64847 | train_balanced_accuracy: 0.67624 | val_accuracy: 0.64233 | val_balanced_accuracy: 0.66136 |  0:11:06s\n",
      "epoch 58 | loss: 0.73601 | train_accuracy: 0.64258 | train_balanced_accuracy: 0.67567 | val_accuracy: 0.63671 | val_balanced_accuracy: 0.66064 |  0:11:17s\n",
      "epoch 59 | loss: 0.73579 | train_accuracy: 0.65566 | train_balanced_accuracy: 0.67899 | val_accuracy: 0.64884 | val_balanced_accuracy: 0.66248 |  0:11:29s\n",
      "epoch 60 | loss: 0.72967 | train_accuracy: 0.63664 | train_balanced_accuracy: 0.67797 | val_accuracy: 0.62985 | val_balanced_accuracy: 0.6612  |  0:11:40s\n",
      "epoch 61 | loss: 0.73273 | train_accuracy: 0.65369 | train_balanced_accuracy: 0.68079 | val_accuracy: 0.64656 | val_balanced_accuracy: 0.66414 |  0:11:52s\n",
      "epoch 62 | loss: 0.72714 | train_accuracy: 0.64995 | train_balanced_accuracy: 0.68028 | val_accuracy: 0.64247 | val_balanced_accuracy: 0.66367 |  0:12:03s\n",
      "epoch 63 | loss: 0.72564 | train_accuracy: 0.65673 | train_balanced_accuracy: 0.68306 | val_accuracy: 0.64879 | val_balanced_accuracy: 0.66488 |  0:12:15s\n",
      "epoch 64 | loss: 0.72557 | train_accuracy: 0.65798 | train_balanced_accuracy: 0.68234 | val_accuracy: 0.65135 | val_balanced_accuracy: 0.66462 |  0:12:26s\n",
      "epoch 65 | loss: 0.7257  | train_accuracy: 0.64379 | train_balanced_accuracy: 0.68264 | val_accuracy: 0.63523 | val_balanced_accuracy: 0.66391 |  0:12:38s\n",
      "epoch 66 | loss: 0.73552 | train_accuracy: 0.64334 | train_balanced_accuracy: 0.67601 | val_accuracy: 0.63714 | val_balanced_accuracy: 0.66137 |  0:12:50s\n",
      "epoch 67 | loss: 0.73494 | train_accuracy: 0.6492  | train_balanced_accuracy: 0.67946 | val_accuracy: 0.64217 | val_balanced_accuracy: 0.66273 |  0:13:02s\n",
      "epoch 68 | loss: 0.72814 | train_accuracy: 0.65272 | train_balanced_accuracy: 0.68206 | val_accuracy: 0.64503 | val_balanced_accuracy: 0.66412 |  0:13:13s\n",
      "epoch 69 | loss: 0.72438 | train_accuracy: 0.64709 | train_balanced_accuracy: 0.68176 | val_accuracy: 0.63984 | val_balanced_accuracy: 0.66414 |  0:13:24s\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n",
    "                    optimizer_params=dict(lr=.02),\n",
    "                    scheduler_params={\"step_size\":20, # how to use learning rate scheduler\n",
    "                                        \"gamma\":0.9},\n",
    "                    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                    mask_type='entmax' # \"sparsemax\"\n",
    "                    )\n",
    "\n",
    "# fit the model \n",
    "clf.fit(\n",
    "    X_train,y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    eval_name=['train', 'val'],\n",
    "    eval_metric=['accuracy', 'balanced_accuracy'],\n",
    "    max_epochs=200 , patience=20,\n",
    "    batch_size=8192, virtual_batch_size=256,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "save_path = clf.save_model('TabNet')\n",
    "\n",
    "val_preds = clf.predict(X_val)\n",
    "train_preds = clf.predict(X_train)\n",
    "test_preds = clf.predict(X_test)\n",
    "\n",
    "val_acc = balanced_accuracy_score(y_val, val_preds)\n",
    "train_acc = balanced_accuracy_score(y_train, train_preds)\n",
    "\n",
    "print(\"Final Balanced Val Accuracy: {}\".format(val_acc), flush=True)\n",
    "print(\"Final Balanced Train Accuracy: {}\".format(train_acc), flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TabNetClassifier' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/isbilla/371/explore.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/isbilla/371/explore.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39m# plot losses\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/isbilla/371/explore.ipynb#ch0000007?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(clf\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/isbilla/371/explore.ipynb#ch0000007?line=3'>4</a>\u001b[0m \u001b[39m# plot accuracy\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/isbilla/371/explore.ipynb#ch0000007?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(clf\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mtrain_accuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TabNetClassifier' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "# plot losses\n",
    "plt.plot(clf.history['loss'])\n",
    "\n",
    "# plot accuracy\n",
    "plt.plot(clf.history['train_accuracy'])\n",
    "plt.plot(clf.history['valid_accuracy'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c942a8df802156eccca4c0073ee5da11d4749cb935a219db40be6fa9a2b39348"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('371')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
